# Google Cloud Platform Deployment Guide

Deploy to single GCE VM using Docker Compose. Start simple, scale later.

---

## ðŸš€ TL;DR - Automated Deployment

The deployment process is now **fully automated** via Taskfile commands:

```bash
# Complete deployment workflow
task gcp:full-deploy

# Or step-by-step:
task gcp:setup           # Configure GCP CLI
task gcp:enable-apis     # Enable required APIs
task gcp:firewall        # Create firewall rules
task gcp:create-vm       # Create VM instance
task gcp:reserve-ip      # Reserve static IP (optional)
task gcp:deploy:initial  # First-time deployment (interactive)
task gcp:systemd         # Setup auto-start service
```

**See [taskfiles/README.md](../../taskfiles/README.md) for all GCP tasks.**

---

## ðŸ› ï¸ Production Operations Quick Reference

Common commands for managing your production deployment:

```bash
# Check deployment status and health
task gcp:status              # Show VM status
task gcp:health              # Check application health
task gcp:ip                  # Get external IP address

# View logs and debugging
task gcp:logs                # View application logs
task gcp:logs:tail           # View last 100 lines
task gcp:ssh                 # SSH into GCP instance

# Docker container management
task gcp:docker:ps           # Show running containers
task gcp:docker:up           # Start all services
task gcp:docker:down         # Stop all services
task gcp:docker:restart      # Restart all services

# Service management
task gcp:restart             # Restart services via systemd
task gcp:deploy:update       # Update to latest code

# Publisher control
task gcp:publisher:start              # Start publisher (default 10 msgs/sec)
task gcp:publisher:start RATE=20      # Start with specific rate
task gcp:publisher:stop               # Stop publisher
task gcp:publisher:configure RATE=15  # Change message rate
task gcp:publisher:stats              # View publisher statistics

# VM lifecycle (cost management)
task gcp:stop                # Stop VM (save money when not in use)
task gcp:start               # Start stopped VM

# Maintenance
task gcp:backup              # Create Prometheus/Grafana backups
task gcp:quick-check         # Quick health and status check
```

**Service URLs (replace `$EXTERNAL_IP` with your IP from `task gcp:ip`):**
- WebSocket: `ws://$EXTERNAL_IP:3004/ws`
- Health Check: `http://$EXTERNAL_IP:3004/health`
- Publisher API: `http://$EXTERNAL_IP:3003/control` (use tasks for control)
- Publisher Stats: `http://$EXTERNAL_IP:3003/stats`
- Grafana Dashboard: `http://$EXTERNAL_IP:3010` (admin/admin)
- Prometheus: `http://$EXTERNAL_IP:9091`

---

## Quick Start

**Phase 1 (Now):** Single VM, IP address only, no SSL (Automated via tasks)
**Phase 2 (Later):** Add domain + SSL
**Phase 3 (Future):** Add load balancer for scaling

---

## Phase 1: Deploy to Single VM

> **Note:** All commands below are available as automated tasks. See the TL;DR section above.

### Prerequisites

```bash
# Install gcloud CLI (macOS - already installed âœ“)
# Verify installation
gcloud --version

# Authenticate
gcloud auth login

# Create new project (or use existing)
export PROJECT_ID="odin-ws-server"
gcloud config set project $PROJECT_ID

# Set default region/zone
export REGION=us-central1
export ZONE=us-central1-a
gcloud config set compute/region $REGION
gcloud config set compute/zone $ZONE
```

**OR** use automated task: `task gcp:setup`

### Step 1: Enable APIs

**Automated:** `task gcp:enable-apis`

**Manual:**
```bash
# Enable required APIs
gcloud services enable compute.googleapis.com
# gcloud services enable logging.googleapis.com
# gcloud services enable monitoring.googleapis.com

# Verify
gcloud services list --enabled
```

**OR** use automated task: `task gcp:enable-apis`

### Step 2: Create Firewall Rules

**Automated:** `task gcp:firewall`

**Manual:**
```bash
# Allow SSH (default - already exists)
gcloud compute firewall-rules list | grep default-allow-ssh

# Allow HTTP (port 3004 for WebSocket - no SSL yet)
gcloud compute firewall-rules create allow-websocket \
  --allow tcp:3004 \
  --source-ranges 0.0.0.0/0 \
  --target-tags websocket-server \
  --description "Allow WebSocket connections"

# Allow Grafana (port 3010 - optional, for monitoring)
gcloud compute firewall-rules create allow-grafana \
  --allow tcp:3010 \
  --source-ranges 0.0.0.0/0 \
  --target-tags websocket-server \
  --description "Allow Grafana access"

# Verify
gcloud compute firewall-rules list --filter="name~'allow-'"
```

**OR** use automated task: `task gcp:firewall`

### Step 3: Create VM Instance

**Automated:** `task gcp:create-vm`

**Manual:**
```bash
# Create VM 
# Note $ZONE has to be defined
gcloud compute instances create odin-ws-server \
  --zone=$ZONE \
  --machine-type=e2-medium \
  --image-family=ubuntu-2404-lts-amd64 \
  --image-project=ubuntu-os-cloud \
  --boot-disk-size=30GB \
  --boot-disk-type=pd-balanced \
  --tags=websocket-server \
  --metadata=startup-script='#!/bin/bash
    apt-get update
    apt-get install -y apt-transport-https ca-certificates curl software-properties-common
    curl -fsSL https://get.docker.com -o get-docker.sh
    sh get-docker.sh
    apt-get install -y docker-compose-plugin git
    curl -sL https://taskfile.dev/install.sh | sh -s -- -d -b /usr/local/bin
    useradd -m -s /bin/bash -G docker deploy
    echo "Startup completed" > /var/log/startup-complete.log'

# Wait for instance to be ready (2-3 minutes)
echo "Waiting for instance to start..."
sleep 120

# Get external IP
export EXTERNAL_IP=$(gcloud compute instances describe odin-ws-server \
  --zone=$ZONE \
  --format="get(networkInterfaces[0].accessConfigs[0].natIP)")

echo "===================="
echo "VM Created!"
echo "External IP: $EXTERNAL_IP"
echo "===================="
echo ""
echo "Save this IP - you'll need it to connect"
echo "WebSocket URL: ws://$EXTERNAL_IP:3004/ws"
echo "Grafana URL: http://$EXTERNAL_IP:3010"
```

**OR** use automated task: `task gcp:create-vm`

### Step 4: Reserve Static IP (Optional but Recommended)

**Automated:** `task gcp:reserve-ip`

**Manual:**
```bash
# Create static IP
# Note $REGION has to be defined
gcloud compute addresses create odin-ws-static-ip --region=$REGION

# Get the IP address
STATIC_IP=$(gcloud compute addresses describe odin-ws-static-ip \
  --region=$REGION \
  --format="get(address)")

echo "Static IP: $STATIC_IP"

# Assign to instance
gcloud compute instances delete-access-config odin-ws-server \
  --access-config-name="external-nat" \
  --zone=$ZONE

gcloud compute instances add-access-config odin-ws-server \
  --access-config-name="external-nat" \
  --address=$STATIC_IP \
  --zone=$ZONE

# Update EXTERNAL_IP
export EXTERNAL_IP=$STATIC_IP

echo "Static IP assigned: $EXTERNAL_IP"
```

**OR** use automated task: `task gcp:reserve-ip`

### Step 5: SSH and Setup Application

**Automated:** `task gcp:deploy:initial` (follow interactive prompts)

**Manual:**
```bash
# SSH into instance
gcloud compute ssh odin-ws-server --zone=$ZONE

# Switch to deploy user
sudo su - deploy

# Clone repository
git clone https://github.com/yourorg/ws_poc.git
cd ws_poc

# Create production environment file
cat > .env.production << 'EOF'
NATS_URL=nats://nats:4222
TOKENS=BTC,ETH,SOL,DOGE,ODIN
PORT=3003
NODE_ENV=production
GF_SECURITY_ADMIN_PASSWORD=CHANGE_THIS_STRONG_PASSWORD
EOF

chmod 600 .env.production

# Create production docker-compose override
cat > docker-compose.prod.yml << 'EOF'
version: "3.8"

services:
  ws-go:
    restart: always
    ports:
      - "3004:3002"  # Expose to external
    logging:
      driver: "json-file"
      options:
        max-size: "10m"
        max-file: "3"

  publisher:
    restart: always
    logging:
      driver: "json-file"
      options:
        max-size: "10m"
        max-file: "3"

  nats:
    restart: always
    logging:
      driver: "json-file"
      options:
        max-size: "10m"
        max-file: "3"

  prometheus:
    restart: always
    command:
      - '--config.file=/etc/prometheus/prometheus.yml'
      - '--storage.tsdb.path=/prometheus'
      - '--storage.tsdb.retention.time=30d'
    logging:
      driver: "json-file"
      options:
        max-size: "10m"
        max-file: "3"

  grafana:
    restart: always
    ports:
      - "3010:3000"  # Expose to external
    environment:
      - GF_SECURITY_ADMIN_PASSWORD=${GF_SECURITY_ADMIN_PASSWORD}
      - GF_SERVER_ROOT_URL=http://${EXTERNAL_IP}:3010
    logging:
      driver: "json-file"
      options:
        max-size: "10m"
        max-file: "3"

  loki:
    restart: always
    logging:
      driver: "json-file"
      options:
        max-size: "10m"
        max-file: "3"

  promtail:
    restart: always
    logging:
      driver: "json-file"
      options:
        max-size: "10m"
        max-file: "3"
EOF
```

**Note:** For automated deployment, follow instructions from `task gcp:deploy:initial`

### Step 6: Build and Start Services

**From VM after initial setup:**
```bash
# Build Docker images
task build:docker

# Start all services
docker compose -f docker-compose.yml -f docker-compose.prod.yml up -d

# Verify all containers running
docker compose ps

# Expected output: All containers should be "Up"
# NAME                COMMAND                  SERVICE      STATUS
# odin-ws-go          "./odin-ws-server"       ws-go        Up
# odin-nats           "nats-server ..."        nats         Up
# odin-publisher      "node dist/publisher.js" publisher    Up
# odin-prometheus     "/bin/prometheus ..."    prometheus   Up
# odin-grafana        "/run.sh"                grafana      Up
# odin-loki           "/usr/bin/loki ..."      loki         Up
# odin-promtail       "/usr/bin/promtail ..."  promtail     Up

# Check logs
docker compose logs -f ws-go
# Press Ctrl+C to exit

# Test health endpoint
curl http://localhost:3004/health | jq '.'
```

### Step 7: Create Systemd Service (Auto-start on Reboot)

**Automated:** `task gcp:systemd`

**Manual:**
```bash
# Exit from deploy user
exit

# Create systemd service
sudo tee /etc/systemd/system/odin-ws.service > /dev/null << 'EOF'
[Unit]
Description=Odin WebSocket Server
Requires=docker.service
After=docker.service network-online.target
Wants=network-online.target

[Service]
Type=oneshot
RemainAfterExit=yes
WorkingDirectory=/home/deploy/ws_poc
ExecStart=/usr/bin/docker compose -f docker-compose.yml -f docker-compose.prod.yml up -d
ExecStop=/usr/bin/docker compose -f docker-compose.yml -f docker-compose.prod.yml down
User=deploy
Group=deploy
Environment="EXTERNAL_IP=%EXTERNAL_IP%"

[Install]
WantedBy=multi-user.target
EOF

# Replace placeholder with actual IP
sudo sed -i "s/%EXTERNAL_IP%/$EXTERNAL_IP/" /etc/systemd/system/odin-ws.service

# Enable service
sudo systemctl daemon-reload
sudo systemctl enable odin-ws
sudo systemctl start odin-ws
sudo systemctl status odin-ws

# Exit SSH
exit
```

### Step 8: Verify Deployment from Local Machine

**Automated:** `task gcp:health`

**Manual:**
```bash
# Test health endpoint
curl http://$EXTERNAL_IP:3004/health | jq '.'

# Expected output:
# {
#   "status": "healthy",
#   "healthy": true,
#   "checks": {
#     "nats": { "status": "connected", "healthy": true },
#     ...
#   }
# }

# Test WebSocket connection
npm install -g wscat  # If not installed
wscat -c ws://$EXTERNAL_IP:3004/ws

# Should connect and receive price updates

# Open Grafana
open http://$EXTERNAL_IP:3010
# Login: admin / CHANGE_THIS_STRONG_PASSWORD
```

---

## Testing WebSocket Connection

### From Browser Console

```javascript
// Open http://$EXTERNAL_IP:3010 (or any HTTP page)
// Open browser console and run:

const ws = new WebSocket('ws://YOUR_IP:3004/ws');

ws.onopen = () => console.log('Connected!');
ws.onmessage = (event) => console.log('Message:', event.data);
ws.onerror = (error) => console.error('Error:', error);
ws.onclose = () => console.log('Disconnected');
```

### Using wscat

```bash
# Connect
wscat -c ws://$EXTERNAL_IP:3004/ws

# Should see price updates:
# < {"type":"price_update","token":"BTC","price":45000.23,...}
# < {"type":"price_update","token":"ETH","price":3200.45,...}
```

### Run Stress Test

```bash
# From your local machine (where you have the code)
cd /Volumes/Dev/Codev/Toniq/ws_poc

# Update stress test script to use your IP
# Edit scripts/stress-test-high-load.cjs
# Change: const WS_URL = 'ws://YOUR_IP:3004';

# Or pass as environment variable
WS_HOST=$EXTERNAL_IP task test:light

# Monitor in Grafana
open http://$EXTERNAL_IP:3010
```

---

## Monitoring

### View Logs

```bash
# SSH to instance
gcloud compute ssh odin-ws-server --zone=$ZONE

# View all logs
sudo su - deploy
cd ws_poc
docker compose logs -f

# View specific service
docker compose logs -f ws-go
docker compose logs -f nats
docker compose logs -f publisher

# View last 100 lines
docker compose logs --tail=100 ws-go
```

### Grafana Dashboards

```bash
# Open Grafana
open http://$EXTERNAL_IP:3010

# Default dashboards:
# 1. WebSocket Metrics Dashboard (Prometheus)
#    - Active connections
#    - Message throughput
#    - CPU/Memory usage
#
# 2. WebSocket Logs Stream (Loki)
#    - Real-time logs
#    - Filter by container
```

### Cloud Monitoring (GCP Console)

```bash
# View VM metrics
echo "https://console.cloud.google.com/compute/instancesDetail/zones/$ZONE/instances/odin-ws-server?project=$PROJECT_ID&tab=monitoring"

# CPU, memory, disk, network
# Auto-collected by Google Cloud
```

---

## Maintenance

### Update Application

```bash
# SSH to instance
gcloud compute ssh odin-ws-server --zone=$ZONE

# Switch to deploy user
sudo su - deploy
cd ws_poc

# Pull latest code
git pull origin main

# Rebuild and restart
docker compose -f docker-compose.yml -f docker-compose.prod.yml build
docker compose -f docker-compose.yml -f docker-compose.prod.yml up -d

# Verify
docker compose ps
curl http://localhost:3004/health | jq '.'
```

### Backup Data

```bash
# SSH to instance
gcloud compute ssh odin-ws-server --zone=$ZONE

# Create backup directory
sudo mkdir -p /backups

# Backup script
sudo tee /opt/backup-odin.sh > /dev/null << 'EOF'
#!/bin/bash
BACKUP_DIR=/backups
DATE=$(date +%Y%m%d-%H%M%S)

mkdir -p $BACKUP_DIR

# Backup Prometheus data
docker run --rm \
  -v ws_poc_prometheus_data:/data \
  -v $BACKUP_DIR:/backup \
  alpine tar czf /backup/prometheus-$DATE.tar.gz /data

# Backup Grafana data
docker run --rm \
  -v ws_poc_grafana_data:/data \
  -v $BACKUP_DIR:/backup \
  alpine tar czf /backup/grafana-$DATE.tar.gz /data

# Keep last 7 days
find $BACKUP_DIR -name "*.tar.gz" -mtime +7 -delete

echo "Backup completed: $DATE"
EOF

sudo chmod +x /opt/backup-odin.sh

# Run backup manually
sudo /opt/backup-odin.sh

# Schedule daily backup (2 AM)
sudo crontab -e
# Add: 0 2 * * * /opt/backup-odin.sh >> /var/log/odin-backup.log 2>&1
```

### Restart Services

```bash
# Restart all
gcloud compute ssh odin-ws-server --zone=$ZONE --command="sudo systemctl restart odin-ws"

# Or SSH in and restart specific service
gcloud compute ssh odin-ws-server --zone=$ZONE
sudo su - deploy
cd ws_poc
docker compose restart ws-go
```

### Check Resource Usage

```bash
# SSH to instance
gcloud compute ssh odin-ws-server --zone=$ZONE

# Check system resources
htop  # If installed: sudo apt install htop

# Check disk usage
df -h

# Check memory
free -h

# Check Docker resources
docker stats
```

---

## Phase 2: Add Domain + SSL (Later)

When you have a domain:

### Option A: Real Domain

```bash
# 1. Buy domain (e.g., from Cloudflare, Namecheap)
# 2. Add DNS A record:
#    ws.yourdomain.com  A  $EXTERNAL_IP

# 3. SSH to instance
gcloud compute ssh odin-ws-server --zone=$ZONE

# 4. Install Nginx + Certbot
sudo apt install -y nginx certbot python3-certbot-nginx

# 5. Configure Nginx (see nginx config below)

# 6. Get SSL certificate
sudo certbot --nginx -d ws.yourdomain.com

# 7. Update firewall
gcloud compute firewall-rules create allow-https \
  --allow tcp:443 \
  --source-ranges 0.0.0.0/0 \
  --target-tags websocket-server

# 8. Connect to wss://ws.yourdomain.com/ws
```

### Option B: Free Subdomain (nip.io)

```bash
# Use magic DNS: $EXTERNAL_IP.nip.io
# Example: 35.123.45.67.nip.io resolves to 35.123.45.67

# Install Nginx + Certbot
sudo apt install -y nginx certbot python3-certbot-nginx

# Get SSL for nip.io domain
sudo certbot --nginx -d $EXTERNAL_IP.nip.io

# Connect to: wss://$EXTERNAL_IP.nip.io/ws
```

### Nginx Configuration (for SSL)

```nginx
# /etc/nginx/sites-available/websocket
upstream websocket_backend {
    server 127.0.0.1:3004;
    keepalive 64;
}

# HTTP to HTTPS redirect
server {
    listen 80;
    server_name ws.yourdomain.com;
    return 301 https://$host$request_uri;
}

# HTTPS WebSocket
server {
    listen 443 ssl http2;
    server_name ws.yourdomain.com;

    # SSL certificates (added by Certbot)
    ssl_certificate /etc/letsencrypt/live/ws.yourdomain.com/fullchain.pem;
    ssl_certificate_key /etc/letsencrypt/live/ws.yourdomain.com/privkey.pem;

    ssl_protocols TLSv1.2 TLSv1.3;

    location /ws {
        proxy_pass http://websocket_backend;
        proxy_http_version 1.1;
        proxy_set_header Upgrade $http_upgrade;
        proxy_set_header Connection "upgrade";
        proxy_set_header Host $host;
        proxy_set_header X-Real-IP $remote_addr;

        proxy_read_timeout 86400s;
        proxy_send_timeout 86400s;
    }

    location /health {
        proxy_pass http://websocket_backend/health;
    }
}
```

---

## Phase 3: Add Load Balancer (Future Scaling)

When you need to scale beyond 1 VM:

```bash
# 1. Create instance template from existing VM
gcloud compute instance-templates create odin-ws-template \
  --source-instance=odin-ws-server \
  --source-instance-zone=$ZONE

# 2. Create managed instance group
gcloud compute instance-groups managed create odin-ws-group \
  --base-instance-name=odin-ws \
  --template=odin-ws-template \
  --size=3 \
  --zone=$ZONE

# 3. Create health check
gcloud compute health-checks create http odin-ws-health \
  --port=3004 \
  --request-path=/health

# 4. Create backend service
gcloud compute backend-services create odin-ws-backend \
  --protocol=HTTP \
  --health-checks=odin-ws-health \
  --global \
  --session-affinity=CLIENT_IP

# 5. Add instance group to backend
gcloud compute backend-services add-backend odin-ws-backend \
  --instance-group=odin-ws-group \
  --instance-group-zone=$ZONE \
  --global

# 6. Create load balancer (see detailed steps in architecture docs)
```

---

## Taskfile Integration

**âœ… Already implemented!** All GCP tasks are available in `taskfiles/deploy-gcp.yml`.

### Available GCP Tasks

```bash
# Infrastructure
task gcp:setup           # Configure gcloud CLI
task gcp:enable-apis     # Enable GCP APIs
task gcp:firewall        # Create firewall rules
task gcp:create-vm       # Create VM instance
task gcp:reserve-ip      # Reserve static IP

# Deployment
task gcp:deploy:initial  # First-time deployment
task gcp:deploy:update   # Update existing deployment
task gcp:systemd         # Setup systemd auto-start

# Operations
task gcp:ssh             # SSH into instance
task gcp:ip              # Get external IP
task gcp:health          # Check deployment health
task gcp:logs            # View application logs
task gcp:logs:tail       # View last 100 lines
task gcp:restart         # Restart services

# VM Lifecycle
task gcp:start           # Start VM
task gcp:stop            # Stop VM (save money)
task gcp:status          # Show VM status
task gcp:delete          # Delete VM (WARNING!)

# Maintenance
task gcp:backup          # Create backups

# Combined Workflows
task gcp:full-deploy     # Complete deployment workflow
task gcp:quick-check     # Quick health and status check
```

### Environment Variable Overrides

```bash
# Custom project/region/zone
export GCP_PROJECT_ID=my-project
export GCP_REGION=us-west1
export GCP_ZONE=us-west1-a
task gcp:create-vm

# Custom machine type
export GCP_MACHINE_TYPE=e2-standard-2
task gcp:create-vm
```

See full implementation in `taskfiles/deploy-gcp.yml`.

---

## CI/CD (Optional)

### GitHub Actions Deployment

```yaml
# .github/workflows/deploy-gcp.yml
name: Deploy to GCP

on:
  push:
    branches: [main]
  workflow_dispatch:

env:
  PROJECT_ID: odin-ws-server
  ZONE: us-central1-a
  INSTANCE: odin-ws-server

jobs:
  deploy:
    runs-on: ubuntu-latest

    steps:
      - name: Checkout
        uses: actions/checkout@v4

      - name: Authenticate to Google Cloud
        uses: google-github-actions/auth@v2
        with:
          credentials_json: ${{ secrets.GCP_SA_KEY }}

      - name: Set up Cloud SDK
        uses: google-github-actions/setup-gcloud@v2

      - name: Deploy
        run: |
          gcloud compute ssh $INSTANCE \
            --zone=$ZONE \
            --command="sudo su - deploy -c 'cd ws_poc && \
              git pull origin main && \
              docker compose -f docker-compose.yml -f docker-compose.prod.yml build && \
              docker compose -f docker-compose.yml -f docker-compose.prod.yml up -d'"

      - name: Health Check
        run: |
          sleep 10
          IP=$(gcloud compute instances describe $INSTANCE \
            --zone=$ZONE \
            --format="get(networkInterfaces[0].accessConfigs[0].natIP)")
          curl -f http://$IP:3004/health
```

**Setup:**
1. Create service account in GCP with Compute Admin role
2. Download JSON key
3. Add to GitHub secrets as `GCP_SA_KEY`

---

## Cost Breakdown

### Single e2-medium VM

| Item | Spec | Monthly Cost |
|------|------|--------------|
| e2-medium | 2 vCPU, 4GB RAM | ~$27.40 |
| Static IP (optional) | 1 IP | $3.00 |
| Standard disk | 30GB | $1.20 |
| Egress | First 1GB free | $5-20 |
| **Total** | | **$36-51/month** |

### Cost Optimization

```bash
# Use preemptible/spot instance (60-91% cheaper)
# Warning: Can be terminated at any time, not for production
gcloud compute instances create odin-ws-server \
  --zone=$ZONE \
  --machine-type=e2-medium \
  --provisioning-model=SPOT \
  --instance-termination-action=STOP
  # Cost: ~$8/month instead of $27

# Or use committed use discount
# 1-year commit: 37% discount
# 3-year commit: 55% discount
```

---

## Troubleshooting

### Can't connect to WebSocket

```bash
# Check firewall
gcloud compute firewall-rules list | grep allow-websocket

# Check if container is running
gcloud compute ssh odin-ws-server --zone=$ZONE
docker compose ps

# Check logs
docker compose logs ws-go

# Check if port is listening
netstat -tlnp | grep 3004
```

### Container won't start

```bash
# SSH to instance
gcloud compute ssh odin-ws-server --zone=$ZONE

# Check logs
sudo su - deploy
cd ws_poc
docker compose logs

# Check disk space
df -h

# Restart all
docker compose -f docker-compose.yml -f docker-compose.prod.yml restart
```

### High CPU/Memory

```bash
# Check resource usage
docker stats

# Check system resources
htop

# Upgrade VM if needed
gcloud compute instances stop odin-ws-server --zone=$ZONE
gcloud compute instances set-machine-type odin-ws-server \
  --machine-type=e2-standard-2 \
  --zone=$ZONE
gcloud compute instances start odin-ws-server --zone=$ZONE
```

---

## Quick Reference

### Essential Commands

```bash
# SSH
gcloud compute ssh odin-ws-server --zone=us-central1-a

# Get IP
gcloud compute instances describe odin-ws-server \
  --zone=us-central1-a \
  --format="get(networkInterfaces[0].accessConfigs[0].natIP)"

# View logs
gcloud compute ssh odin-ws-server --zone=us-central1-a \
  --command="sudo su - deploy -c 'cd ws_poc && docker compose logs -f'"

# Restart services
gcloud compute ssh odin-ws-server --zone=us-central1-a \
  --command="sudo systemctl restart odin-ws"

# Stop VM (save money when not using)
gcloud compute instances stop odin-ws-server --zone=us-central1-a

# Start VM
gcloud compute instances start odin-ws-server --zone=us-central1-a
```

### URLs

```bash
# Get your IP first
IP=$(gcloud compute instances describe odin-ws-server \
  --zone=us-central1-a \
  --format="get(networkInterfaces[0].accessConfigs[0].natIP)")

# Access URLs
echo "WebSocket: ws://$IP:3004/ws"
echo "Health: http://$IP:3004/health"
echo "Grafana: http://$IP:3010"
```

---

## Next Steps

1. âœ… Run deployment commands above
2. âœ… Get your external IP
3. âœ… Test WebSocket connection
4. âœ… Open Grafana and check dashboards
5. âœ… Run stress tests
6. ðŸ“… Later: Add domain + SSL
7. ðŸ“… Future: Add load balancer for scaling

**Deployment time: 15-30 minutes**

Ready to deploy!
