package main

import (
	"sync"
	"time"
)

// TokenBucket implements rate limiting using the token bucket algorithm
// This is the industry-standard algorithm for rate limiting used by:
// - AWS API Gateway
// - Google Cloud Load Balancer
// - Cloudflare
// - Stripe API
// - Most WebSocket platforms
//
// How Token Bucket Works:
// ┌─────────────────────────────┐
// │   Bucket (Max 100 tokens)   │  ← Capacity (burst allowance)
// │                             │
// │   🪙🪙🪙🪙🪙🪙🪙🪙🪙🪙       │  ← Current tokens (85)
// └─────────────────────────────┘
//      ↓ Tokens refill at fixed rate (10/sec)
//      ↓ Each request consumes 1 token
//      ↓ Reject if bucket empty
//
// Example scenario:
//   Bucket: 100 tokens max
//   Refill: 10 tokens/second
//   Client behavior:
//   - Sends 100 requests instantly → All succeed (burst allowed)
//   - Bucket now empty
//   - Must wait 1 second for 10 tokens to refill
//   - Can send 10 more requests
//   - Sustained rate: 10 requests/second
//
// Why token bucket vs alternatives:
//
// 1. Leaky Bucket:
//    - Smooths traffic (no bursts)
//    - Bad for trading: Users need bursts (rapid order entry during volatility)
//
// 2. Fixed Window:
//    - Simple but has "burst at window edge" problem
//    - Example: 100 req/min limit
//      - Send 100 at 10:00:59 → OK
//      - Send 100 at 10:01:00 → OK
//      - 200 requests in 2 seconds! Not what we wanted
//
// 3. Sliding Window:
//    - More accurate than fixed window
//    - Complex to implement
//    - Higher memory usage
//
// 4. Token Bucket (our choice):
//    - Allows controlled bursts (important for trading)
//    - Simple to implement
//    - Low memory (8 bytes per client)
//    - Industry standard
//
// For trading platform:
//   Burst: User enters 20 orders during market spike → Allowed
//   Sustained: User sends 1000 orders/sec continuously → Rate limited
//
type TokenBucket struct {
	// Current number of tokens in bucket
	// Float64 for fractional token accumulation
	// Example: 0.5 tokens + 0.3 seconds × 10 tokens/sec = 3.5 tokens
	tokens float64

	// Maximum tokens bucket can hold (burst capacity)
	// Determines how many requests can be made instantly
	// Trading platform examples:
	//   - Retail users: 100 tokens (handle order entry flurry)
	//   - Market makers: 1000 tokens (rapid quote updates)
	//   - Admin endpoints: 10 tokens (prevent abuse)
	maxTokens float64

	// Tokens added per second (sustained rate limit)
	// This is the long-term rate limit
	// Examples:
	//   - REST API: 10/sec (typical web API)
	//   - WebSocket messages: 50/sec (real-time updates)
	//   - Trading orders: 20/sec (prevent fat finger)
	//   - Market data subscriptions: 5/sec (prevent subscription spam)
	refillRate float64

	// Last time we refilled tokens
	// Used to calculate how many tokens to add:
	//   tokensToAdd = (now - lastRefill) × refillRate
	lastRefill time.Time

	// Mutex for thread safety
	// Multiple goroutines may check rate limit for same client:
	//   - readPump() checking incoming messages
	//   - handleClientMessage() processing requests
	//   - metrics goroutine reading current tokens
	mu sync.Mutex
}

// NewTokenBucket creates a token bucket rate limiter
//
// Parameters:
//   maxTokens  - Burst capacity (how many instant requests allowed)
//   refillRate - Sustained rate (requests per second long-term)
//
// Common configurations:
//
// Retail Trading (our default):
//   NewTokenBucket(100, 10)
//   - Allows: 100 order burst, then 10 orders/second sustained
//   - Use case: User rapidly entering orders during market volatility
//
// Institutional Trading:
//   NewTokenBucket(1000, 100)
//   - Allows: 1000 message burst, then 100/second sustained
//   - Use case: Market maker updating quotes continuously
//
// Mobile App:
//   NewTokenBucket(20, 5)
//   - Allows: 20 request burst, then 5/second sustained
//   - Use case: Prevent accidental DoS from buggy mobile client
//
// Admin Actions:
//   NewTokenBucket(10, 1)
//   - Allows: 10 request burst, then 1/second sustained
//   - Use case: Sensitive operations (balance updates, withdrawals)
func NewTokenBucket(maxTokens, refillRate float64) *TokenBucket {
	return &TokenBucket{
		tokens:     maxTokens, // Start with full bucket
		maxTokens:  maxTokens,
		refillRate: refillRate,
		lastRefill: time.Now(),
	}
}

// TryConsume attempts to consume N tokens from bucket
// Returns true if successful (request allowed), false if insufficient tokens (rate limited)
//
// This implements the core rate limiting logic:
// 1. Refill tokens based on time elapsed
// 2. Cap at maximum (prevent infinite accumulation)
// 3. Check if enough tokens available
// 4. Consume tokens if available
//
// Thread-safe: Multiple goroutines can call concurrently
// Performance: ~100ns per call (10M checks/second per CPU core)
//
// Example call flow:
//   bucket := NewTokenBucket(100, 10)
//   bucket.TryConsume(1) → true (99 tokens left)
//   bucket.TryConsume(1) → true (98 tokens left)
//   ... 98 more calls ...
//   bucket.TryConsume(1) → false (0 tokens, RATE LIMITED)
//   time.Sleep(1 * time.Second)
//   bucket.TryConsume(1) → true (10 tokens refilled)
func (tb *TokenBucket) TryConsume(tokens float64) bool {
	tb.mu.Lock()
	defer tb.mu.Unlock()

	// Calculate tokens to add based on time elapsed
	now := time.Now()
	elapsed := now.Sub(tb.lastRefill).Seconds()

	// Add refilled tokens
	// Example: 0.5 seconds elapsed × 10 tokens/sec = 5 tokens added
	tb.tokens += elapsed * tb.refillRate

	// Cap at maximum capacity
	// Without this, client could accumulate infinite tokens by not sending requests
	// Example: User doesn't trade for 1 hour → 36,000 tokens accumulated
	//          Then spams 36,000 orders instantly → Server overload
	// With cap: User gets maximum 100 burst, no matter how long they wait
	if tb.tokens > tb.maxTokens {
		tb.tokens = tb.maxTokens
	}

	tb.lastRefill = now

	// Check if enough tokens available
	if tb.tokens >= tokens {
		tb.tokens -= tokens
		return true // Request allowed
	}

	return false // Rate limited
}

// RateLimiter manages per-client rate limits
// Each client gets their own token bucket
// Memory usage: ~100 bytes per client × 10,000 clients = 1MB (negligible)
//
// Design pattern: sync.Map for concurrent access
// Why sync.Map vs map[int64]*TokenBucket with mutex:
//   - Optimized for case where entries change infrequently (client connects/disconnects)
//   - Read-heavy workload (many CheckLimit calls, few LoadOrStore)
//   - Better performance under high concurrency
//
// Alternative considered: Single global bucket
//   Pros: Simple, low memory
//   Cons: One abusive client affects all users (unfair)
//   Decision: Per-client is industry standard
type RateLimiter struct {
	// Map of clientID → TokenBucket
	// Automatically cleans up on disconnect (RemoveClient called from readPump defer)
	clients sync.Map // map[int64]*TokenBucket
}

// NewRateLimiter creates a rate limiter for managing client limits
func NewRateLimiter() *RateLimiter {
	return &RateLimiter{}
}

// CheckLimit verifies if client can perform action
// Returns true if allowed, false if rate limited
//
// For trading platform, we enforce different limits per action type:
// - WebSocket messages (incoming): 100 burst, 10/sec sustained
// - Order submissions: 20 burst, 5/sec sustained
// - Market data subscriptions: 100 burst, 5/sec sustained
// - Account queries: 50 burst, 10/sec sustained
//
// Current implementation: Single limit for all actions (simplicity)
// Production evolution: Multiple buckets per client (by action type)
//
// Rate limit values chosen based on:
//   100 burst: Active trader during volatility enters ~50 orders/minute
//              100 burst handles 2 minutes of rapid entry
//   10/sec sustained: Professional trader averages ~600 orders/hour
//                     = 10/min sustained average
//                     Peak: 10/sec for short bursts
//
// Comparison to industry:
//   - Coinbase: 10 orders/second
//   - Binance: 10 orders/second per symbol, 100/sec total
//   - Interactive Brokers: 50 orders/second
//   - Our limit: Competitive for retail, may need increase for institutional
func (rl *RateLimiter) CheckLimit(clientID int64) bool {
	// Get existing bucket or create new one
	// LoadOrStore is atomic: Only one goroutine creates bucket for new client
	bucket, _ := rl.clients.LoadOrStore(clientID, NewTokenBucket(100, 10))

	return bucket.(*TokenBucket).TryConsume(1)
}

// RemoveClient cleans up rate limit state on disconnect
// Important for memory management:
//   Without cleanup: 10,000 clients connect/disconnect per day = 10,000 buckets leak
//   With cleanup: Memory usage stays constant
//
// Called from readPump() defer (guaranteed to run on disconnect)
func (rl *RateLimiter) RemoveClient(clientID int64) {
	rl.clients.Delete(clientID)
}
