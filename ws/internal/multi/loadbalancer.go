package multi

import (
	"context"
	"encoding/json"
	"fmt"
	"math"
	"net/http"
	"net/url"
	"sync"
	"time"

	"github.com/adred-codev/ws_poc/internal/shared/monitoring"
	"github.com/rs/zerolog"
)

// LoadBalancer distributes incoming WebSocket connections to available shards.
// It uses a "least connections" strategy to ensure even distribution.
type LoadBalancer struct {
	addr    string
	shards  []*Shard
	proxies []http.Handler // One WebSocket proxy per shard
	logger  zerolog.Logger

	// HTTP timeouts (configured from platform config)
	httpReadTimeout  time.Duration
	httpWriteTimeout time.Duration
	httpIdleTimeout  time.Duration

	ctx    context.Context
	cancel context.CancelFunc
	wg     sync.WaitGroup
}

// LoadBalancerConfig holds configuration for the LoadBalancer
type LoadBalancerConfig struct {
	Addr   string
	Shards []*Shard
	Logger zerolog.Logger

	// HTTP timeouts (for trading platform burst tolerance)
	HTTPReadTimeout  time.Duration
	HTTPWriteTimeout time.Duration
	HTTPIdleTimeout  time.Duration
}

// NewLoadBalancer creates a new LoadBalancer instance.
func NewLoadBalancer(cfg LoadBalancerConfig) (*LoadBalancer, error) {
	if len(cfg.Shards) == 0 {
		return nil, fmt.Errorf("no shards provided to load balancer")
	}

	ctx, cancel := context.WithCancel(context.Background())

	proxies := make([]http.Handler, len(cfg.Shards))
	for i, shard := range cfg.Shards {
		// Parse shard URL - use ws:// scheme for WebSocket proxy
		// CRITICAL: Must include /ws path to match shard's WebSocket endpoint
		shardAddr := shard.GetAddr()
		shardURL, err := url.Parse(fmt.Sprintf("ws://%s/ws", shardAddr))
		if err != nil {
			cancel()
			return nil, fmt.Errorf("failed to parse shard address %s: %w", shardAddr, err)
		}
		// Create custom SlotAwareProxy that fixes slot leak bug
		// Upgrades to WebSocket BEFORE acquiring slot, preventing leaks
		proxies[i] = NewSlotAwareProxy(shard, shardURL, cfg.Logger)

		// Log proxy target (one-time, no performance impact)
		cfg.Logger.Info().
			Int("shard_id", shard.ID).
			Str("target_url", shardURL.String()).
			Msg("Created SlotAwareProxy for shard")
	}

	lb := &LoadBalancer{
		addr:    cfg.Addr,
		shards:  cfg.Shards,
		proxies: proxies,
		logger:  cfg.Logger.With().Str("component", "load_balancer").Logger(),
		// Store HTTP timeouts from config
		httpReadTimeout:  cfg.HTTPReadTimeout,
		httpWriteTimeout: cfg.HTTPWriteTimeout,
		httpIdleTimeout:  cfg.HTTPIdleTimeout,
		ctx:              ctx,
		cancel:           cancel,
	}

	return lb, nil
}

// Start begins the LoadBalancer's HTTP server.
func (lb *LoadBalancer) Start() error {
	lb.logger.Info().Str("address", lb.addr).Msg("LoadBalancer starting")

	mux := http.NewServeMux()
	mux.HandleFunc("/ws", lb.handleWebSocket)
	mux.HandleFunc("/health", lb.handleHealth)

	// Store config in LoadBalancer so we can access timeouts
	// Need to get these from the cfg parameter in Start()
	// For now, we'll need to store cfg in NewLoadBalancer
	server := &http.Server{
		Addr:    lb.addr,
		Handler: mux,
		// Timeouts now configurable for trading platform burst tolerance
		// Defaults in platform/config.go: Read 15s, Write 15s, Idle 60s
		ReadTimeout:    lb.httpReadTimeout,
		WriteTimeout:   lb.httpWriteTimeout,
		IdleTimeout:    lb.httpIdleTimeout,
		MaxHeaderBytes: 1 << 20,
	}

	lb.wg.Add(1)
	go func() {
		// CRITICAL: Panic recovery must be FIRST defer (executes LAST in LIFO order)
		defer monitoring.RecoverPanic(lb.logger, "loadbalancer.ListenAndServe", nil)

		defer lb.wg.Done()
		lb.logger.Info().Str("address", server.Addr).Msg("LoadBalancer listening")
		if err := server.ListenAndServe(); err != nil && err != http.ErrServerClosed {
			lb.logger.Error().Err(err).Msg("LoadBalancer HTTP server error")
		}
	}()

	lb.logger.Info().Msg("LoadBalancer started")
	return nil
}

// Shutdown gracefully stops the LoadBalancer.
func (lb *LoadBalancer) Shutdown() {
	lb.logger.Info().Msg("Shutting down LoadBalancer")
	lb.cancel()
	lb.wg.Wait() // Wait for the Start goroutine to finish
	lb.logger.Info().Msg("LoadBalancer shut down")
}

// handleWebSocket handles incoming WebSocket upgrade requests.
// Selects a shard and delegates to SlotAwareProxy which handles all slot lifecycle management.
func (lb *LoadBalancer) handleWebSocket(w http.ResponseWriter, r *http.Request) {
	// Select shard with most available capacity
	selectedShardIndex, selectedShard := lb.selectShard()
	if selectedShard == nil {
		lb.logger.Warn().Msg("No available shards to accept connection")
		http.Error(w, "Server overloaded", http.StatusServiceUnavailable)
		return
	}

	lb.logger.Debug().
		Int("shard_id", selectedShard.ID).
		Int("available_slots", selectedShard.GetAvailableSlots()).
		Msg("Routing connection to shard proxy")

	// Proxy handles all slot lifecycle management internally
	lb.proxies[selectedShardIndex].ServeHTTP(w, r)
}

// selectShard selects a shard using the "least connections" strategy.
// It also respects the WS_MAX_CONNECTIONS limit per shard.
func (lb *LoadBalancer) selectShard() (int, *Shard) {
	var (
		leastConnections int64 = math.MaxInt64
		selectedShard    *Shard
		selectedIndex    int = -1
	)

	for i, shard := range lb.shards {
		currentConns := shard.GetCurrentConnections()
		maxConns := int64(shard.GetMaxConnections())

		// Skip shards that are at or over capacity
		if currentConns >= maxConns {
			continue
		}

		// Use < to select first shard with fewest connections
		// This reduces bias toward higher-indexed shards
		if currentConns < leastConnections {
			leastConnections = currentConns
			selectedShard = shard
			selectedIndex = i
		}
	}

	return selectedIndex, selectedShard
}

// handleHealth aggregates health status from all shards.
// Returns a simplified health response matching the expected format.
func (lb *LoadBalancer) handleHealth(w http.ResponseWriter, r *http.Request) {
	// Set CORS headers
	w.Header().Set("Access-Control-Allow-Origin", "*")
	w.Header().Set("Access-Control-Allow-Methods", "GET, OPTIONS")
	w.Header().Set("Access-Control-Allow-Headers", "Content-Type")
	w.Header().Set("Content-Type", "application/json")

	// Handle preflight requests
	if r.Method == "OPTIONS" {
		w.WriteHeader(http.StatusOK)
		return
	}

	// Aggregate metrics from all shards and collect per-shard stats
	var totalConnections int64
	var totalMaxConnections int64
	allShardsHealthy := true

	// Build per-shard stats array (zero performance impact - just atomic reads)
	type ShardStats struct {
		ID              int     `json:"id"`
		Connections     int64   `json:"connections"`
		MaxConnections  int     `json:"max_connections"`
		AvailableSlots  int     `json:"available_slots"`
		Utilization     float64 `json:"utilization"`
		Status          string  `json:"status"`
	}
	shardStats := make([]ShardStats, 0, len(lb.shards))

	for _, shard := range lb.shards {
		currentConns := shard.GetCurrentConnections()
		maxConns := int64(shard.GetMaxConnections())
		availableSlots := shard.GetAvailableSlots()

		totalConnections += currentConns
		totalMaxConnections += maxConns

		// Calculate utilization percentage
		utilization := 0.0
		if maxConns > 0 {
			utilization = (float64(currentConns) / float64(maxConns)) * 100
		}

		// Determine shard status
		shardStatus := "available"
		if currentConns >= maxConns {
			shardStatus = "full"
		} else if utilization > 90 {
			shardStatus = "high"
		} else if utilization > 75 {
			shardStatus = "medium"
		}

		// Simple health check: if shard is at over capacity, mark as unhealthy
		if currentConns > maxConns {
			allShardsHealthy = false
		}

		// Add per-shard stats (all atomic reads - zero performance cost)
		shardStats = append(shardStats, ShardStats{
			ID:              shard.ID,
			Connections:     currentConns,
			MaxConnections:  int(maxConns),
			AvailableSlots:  availableSlots,
			Utilization:     utilization,
			Status:          shardStatus,
		})
	}

	// Calculate capacity percentage
	var capacityPercent float64
	if totalMaxConnections > 0 {
		capacityPercent = float64(totalConnections) / float64(totalMaxConnections) * 100
	}

	// Get system-wide CPU/memory metrics (same for all shards - single process)
	// Query from shard 0 (arbitrary choice - all shards share the same metrics)
	cpuPercent, memoryMB := 0.0, 0.0
	if len(lb.shards) > 0 {
		cpuPercent, memoryMB = lb.shards[0].GetSystemStats()
	}

	// Build simplified health response matching expected format
	isHealthy := allShardsHealthy && totalConnections <= totalMaxConnections
	status := "healthy"
	statusCode := http.StatusOK

	if !isHealthy {
		status = "unhealthy"
		statusCode = http.StatusServiceUnavailable
	} else if capacityPercent > 90 {
		status = "degraded"
	}

	response := map[string]interface{}{
		"status":  status,
		"healthy": isHealthy,
		"checks": map[string]interface{}{
			"capacity": map[string]interface{}{
				"current":    int(totalConnections),
				"max":        int(totalMaxConnections),
				"percentage": capacityPercent,
			},
			"cpu": map[string]interface{}{
				"percentage": cpuPercent, // System-wide CPU (all shards share same process)
			},
			"memory": map[string]interface{}{
				"used_mb":    memoryMB,   // System-wide memory (all shards share same heap)
				"percentage": 0.0,        // Could calculate from memory limit if needed
			},
		},
		"shards": shardStats, // Per-shard connection breakdown (zero performance cost)
	}

	w.WriteHeader(statusCode)
	json.NewEncoder(w).Encode(response)
}
