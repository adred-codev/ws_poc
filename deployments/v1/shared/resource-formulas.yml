# =============================================================================
# Resource Calculation Formulas
# =============================================================================
# Purpose: Documentation and future automation of resource calculations
# Reference: Used by capacity planning and configuration scripts

# =============================================================================
# WORKER POOL SIZING
# =============================================================================
worker_pool_size:
  formula: "max(32, CPU_LIMIT * 2)"
  description: "Minimum 32 workers for stability, or 2x CPU cores for parallelism"
  rationale: "Each worker handles broadcast tasks; 2x CPU allows overlap during I/O"
  examples:
    - cpu: 1.0
      result: 32
      note: "Minimum enforced (1.0 * 2 = 2, but min is 32)"
    - cpu: 2.0
      result: 32
      note: "Still minimum (2.0 * 2 = 4)"
    - cpu: 16.0
      result: 32
      note: "Standard for larger instances"

worker_queue_size:
  formula: "WORKER_POOL_SIZE * 100"
  description: "100 pending tasks per worker"
  rationale: "Handles burst of Kafka messages during traffic spikes"
  examples:
    - workers: 32
      result: 3200
    - workers: 64
      result: 6400

# =============================================================================
# GOROUTINE LIMITS
# =============================================================================
max_goroutines:
  formula: "((MAX_CONNECTIONS * 2) + WORKER_POOL_SIZE + 13) * 1.2"
  description: "Connection handlers + workers + overhead with 20% buffer"
  breakdown:
    connection_handlers: "MAX_CONNECTIONS * 2 (readPump + writePump)"
    workers: "WORKER_POOL_SIZE"
    server_overhead: "13 (HTTP server, metrics, monitoring, Kafka consumer)"
    safety_buffer: "20% (Ã— 1.2)"
  examples:
    - connections: 1000
      workers: 32
      calculation: "((1000 * 2) + 32 + 13) * 1.2"
      result: 2454
      rounded: 3000
    - connections: 7000
      workers: 32
      calculation: "((7000 * 2) + 32 + 13) * 1.2"
      result: 16854
      rounded: 17000
    - connections: 12000
      workers: 256
      calculation: "((12000 * 2) + 256 + 13) * 1.2"
      result: 29122
      rounded: 30000

# =============================================================================
# MEMORY CALCULATIONS
# =============================================================================
memory_per_connection:
  total_bytes: 180000
  description: "Total memory per WebSocket connection"
  breakdown:
    client_struct: 
      bytes: 200
      description: "Basic fields, pointers, mutexes"
    send_channel:
      bytes: 131072
      calculation: "256 slots * 512 bytes avg message"
      description: "Buffered outgoing messages"
    replay_buffer:
      bytes: 51200
      calculation: "100 messages * 512 bytes"
      description: "Message gap recovery buffer"
    sequence_generator:
      bytes: 8
      description: "Atomic counter for message sequencing"
    overhead:
      bytes: 2048
      description: "Connection pools, maps, alignment padding"

runtime_overhead:
  total_mb: 128
  breakdown:
    go_runtime_heap: 50
    kafka_client: 20
    goroutine_stacks: 30
    buffer_pools_metrics: 10
    safety_margin: 18

available_memory_for_connections:
  formula: "MEMORY_LIMIT - RUNTIME_OVERHEAD"
  description: "Memory available for connection buffers"

max_connections_from_memory:
  formula: "(AVAILABLE_MEMORY / 180000)"
  description: "Maximum connections based on memory constraint"
  examples:
    - memory_limit_mb: 512
      runtime_overhead_mb: 128
      available_mb: 384
      available_bytes: 402653184
      calculation: "402653184 / 180000"
      result: 2237
    - memory_limit_mb: 4096
      runtime_overhead_mb: 128
      available_mb: 3968
      available_bytes: 4160749568
      calculation: "4160749568 / 180000"
      result: 23115
    - memory_limit_mb: 14848
      runtime_overhead_mb: 128
      available_mb: 14720
      available_bytes: 15443148800
      calculation: "15443148800 / 180000"
      result: 85795

# =============================================================================
# CPU CAPACITY
# =============================================================================
cpu_per_connection:
  percent: 0.002
  description: "Estimated CPU per idle connection (monitoring, heartbeats)"
  note: "Active connections during broadcasts use more CPU"

broadcast_cpu_cost:
  per_message: "0.1ms per 1000 connections"
  description: "CPU time to broadcast one message"
  rate_limit_rationale: "At 25 msg/sec * 10K connections = 25ms/sec = 2.5% CPU"

# =============================================================================
# KAFKA CONSUMER
# =============================================================================
kafka_partitions_per_topic:
  default: 12
  description: "Parallel processing capability"
  note: "Total partitions = TOPICS * PARTITIONS (8 * 12 = 96)"

kafka_consumer_goroutines:
  per_partition: 1
  total_formula: "TOPICS * PARTITIONS"
  example:
    topics: 8
    partitions: 12
    result: 96
    note: "96 goroutines for partition consumers"

# =============================================================================
# CAPACITY TARGETS (Reference)
# =============================================================================
capacity_targets:
  local_development:
    instance: "Docker Desktop"
    cpu: 1.0
    memory_gb: 4
    target_connections: 1000
    worker_pool: 32
    max_goroutines: 3000
  
  gcp_distributed_ws:
    instance: "e2-standard-4"
    cpu: 1.0
    memory_gb: 14.5
    target_connections: 12000
    worker_pool: 256
    max_goroutines: 30000
  
  gcp_distributed_backend:
    instance: "e2-small"
    cpu: 2.0
    memory_gb: 2
    services:
      - "Redpanda (400MB)"
      - "Publisher (256MB)"
      - "Prometheus (256MB)"
      - "Grafana (512MB)"
      - "Loki (256MB)"
      - "Promtail (128MB)"

# =============================================================================
# NOTES
# =============================================================================
# This file is for documentation and future automation only.
# It is NOT loaded by any service directly.
#
# Future enhancement: Use this file to generate .env files automatically
# See: docs/CONFIGURATION_CONSOLIDATION_PLAN.md (Phase 7)
