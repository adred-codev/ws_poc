# =============================================================================
# GCP Production Overrides - MULTI-CORE MODE
# =============================================================================
# Purpose: Override shared/base.env for GCP multi-core production deployment
# Load order: base.env → kafka-topics.env → ports.env → overrides.multi.env → .env.production
# Instance: e2-highcpu-8 (8 vCPU, 8GB RAM)
# Target: 18,000+ connections distributed across 3 shards (6K per shard)
#
# Architecture Notes:
#   - Each shard has its own Kafka consumer group (e.g., ws-server-production-0 through -2)
#   - BroadcastBus coordinates message distribution across all shards
#   - LoadBalancer uses "least connections" strategy for even distribution
#   - Per-shard max connections: WS_MAX_CONNECTIONS / 3 shards (6,000 per shard)

ENVIRONMENT=production-multi

# =============================================================================
# KAFKA CONNECTION
# =============================================================================
# Note: KAFKA_BROKERS is set in .env.production (uses BACKEND_INTERNAL_IP)
# Base consumer group name; shards append -0 through -2 (3 shards total)
KAFKA_GROUP_ID=ws-server-production  # Base name

# =============================================================================
# SHARD CONFIGURATION (Multi-Core Architecture)
# =============================================================================
# Production: 3 shards optimal (empirically better than 7 shards - less overhead)
# Debug: Override in .env.debug (create .env.debug from .env.debug.template)
#
# To enable single-shard debug mode:
#   cp .env.debug.template .env.debug
#   docker-compose -f docker-compose.multi.yml up -d --force-recreate
#
# To return to production mode:
#   rm .env.debug
#   docker-compose -f docker-compose.multi.yml up -d --force-recreate
NUM_SHARDS=3              # Number of shard instances (3 optimal for e2-highcpu-8)
SHARD_BASE_PORT=3002      # First shard port (subsequent shards use 3003, 3004, etc.)
LB_PORT=3001              # LoadBalancer external port
LB_ADDR=:3001             # LoadBalancer bind address

# =============================================================================
# RESOURCE LIMITS (Multi-Core Distribution)
# =============================================================================
# Strategy: Optimal 3-shard configuration (empirically better than 7 shards)
# Reason: Fewer shards = less coordination overhead (Kafka, BroadcastBus, LoadBalancer)
# Previous 7 shards: 4,754/12K (39.6%, 701 conn/core) - too much overhead
# Current 3 shards: 5,180/12K (43.2%, 1,762 conn/core) - proven baseline
# CPU: 7 cores total (3 shards + system + headroom)
# Memory: 7GB total (85% of 8GB, plenty for 3 shards)
WS_CPU_LIMIT=7                # Total CPU limit (3 shards use ~3 cores, rest for system/headroom)
WS_MEMORY_LIMIT=7516192768    # 7 GB (85% of 8GB) - e2-highcpu-8 has less RAM
WS_MAX_CONNECTIONS=18000      # Total connections (divided by shard count: 18K/3 = 6,000 per shard)

# =============================================================================
# RATE LIMITING (Production-validated)
# =============================================================================
WS_MAX_KAFKA_RATE=25         # Kafka message consumption rate per shard
WS_MAX_BROADCAST_RATE=25     # Broadcast rate limit per shard

# =============================================================================
# GOROUTINE LIMIT (Calculated for multi-core capacity)
# =============================================================================
# Formula per shard: ((6,000 × 2) + overhead) × 1.2 ≈ 15,000 per shard
# Total: 45,000 for 3 shards (same as before, plenty of headroom)
WS_MAX_GOROUTINES=45000
