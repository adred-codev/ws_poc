# =============================================================================
# GCP Production Overrides - MULTI-CORE MODE
# =============================================================================
# Purpose: Override shared/base.env for GCP multi-core production deployment
# Load order: base.env → kafka-topics.env → ports.env → overrides.multi.env → .env.production
# Instance: e2-highcpu-8 (8 vCPU, 8GB RAM)
# Target: 18,000+ connections distributed across 3 shards (6K per shard)
#
# Architecture Notes:
#   - Each shard has its own Kafka consumer group (e.g., ws-server-production-0 through -2)
#   - BroadcastBus coordinates message distribution across all shards
#   - LoadBalancer uses "least connections" strategy for even distribution
#   - Per-shard max connections: WS_MAX_CONNECTIONS / 3 shards (6,000 per shard)

ENVIRONMENT=production-multi

# =============================================================================
# KAFKA CONNECTION
# =============================================================================
# Note: KAFKA_BROKERS is set in .env.production (uses BACKEND_INTERNAL_IP)
# Base consumer group name; shards append -0 through -2 (3 shards total)
KAFKA_GROUP_ID=ws-server-production  # Base name

# =============================================================================
# SHARD CONFIGURATION (Multi-Core Architecture)
# =============================================================================
# Production: 3 shards optimal (empirically better than 7 shards - less overhead)
# Debug: Override in .env.debug (create .env.debug from .env.debug.template)
#
# To enable single-shard debug mode:
#   cp .env.debug.template .env.debug
#   docker-compose -f docker-compose.multi.yml up -d --force-recreate
#
# To return to production mode:
#   rm .env.debug
#   docker-compose -f docker-compose.multi.yml up -d --force-recreate
NUM_SHARDS=3              # Number of shard instances (3 optimal for e2-highcpu-8)
SHARD_BASE_PORT=3002      # First shard port (subsequent shards use 3003, 3004, etc.)
LB_PORT=3001              # LoadBalancer external port
LB_ADDR=:3001             # LoadBalancer bind address

# =============================================================================
# RESOURCE LIMITS (Multi-Core Distribution)
# =============================================================================
# Strategy: Optimal 3-shard configuration (empirically better than 7 shards)
# Reason: Fewer shards = less coordination overhead (Kafka, BroadcastBus, LoadBalancer)
# Previous 7 shards: 4,754/12K (39.6%, 701 conn/core) - too much overhead
# Current 3 shards: 5,180/12K (43.2%, 1,762 conn/core) - proven baseline
# CPU: 7 cores total (3 shards + system + headroom)
# Memory: 7GB total (85% of 8GB, plenty for 3 shards)
WS_CPU_LIMIT=7                # Total CPU limit (3 shards use ~3 cores, rest for system/headroom)
WS_MEMORY_LIMIT=7516192768    # 7 GB (85% of 8GB) - e2-highcpu-8 has less RAM
WS_MAX_CONNECTIONS=18000      # Total connections (divided by shard count: 18K/3 = 6,000 per shard)

# =============================================================================
# RATE LIMITING (Production-validated)
# =============================================================================
WS_MAX_KAFKA_RATE=25         # Kafka message consumption rate per shard
WS_MAX_BROADCAST_RATE=25     # Broadcast rate limit per shard

# =============================================================================
# GOROUTINE LIMIT (Calculated for multi-core capacity)
# =============================================================================
# UPDATED: Previous limit (15,000) was too low - goroutine limit exceeded at only 1K connections
# Formula per shard: ((max_connections × 2 goroutines) + workers + overhead) × safety_margin
# Per shard: ((6,000 × 2) + 192 + 500) × 1.3 ≈ 16,600
# Total for 3 shards: 16,600 × 3 = 50,000 (with headroom)
#
# Evidence from logs: "goroutine limit exceeded (15049 > 15000)" at only 999 connections
# Root cause: 999 conn × 2 goroutines + 192 workers + overhead ≈ 2,200 per shard × 3 = 15,000
# Fix: Increase to 50,000 to support full 6K connections per shard
WS_MAX_GOROUTINES=50000
